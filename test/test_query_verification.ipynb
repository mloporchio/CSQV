{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4349209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import struct\n",
    "import subprocess\n",
    "import sys\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7de77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "exec_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ea4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns all records whose location is in the given range.\n",
    "def range_query(df, lx, ly, ux, uy):\n",
    "    return (df[(df.x >= lx) & (df.x <= ux) & (df.y >= ly) & (df.y <= uy)])\n",
    "\n",
    "# Returns the bounding rectangle of a Pandas dataframe.\n",
    "def bounding_rect(df):\n",
    "    return (np.min(df['x']), np.min(df['y']), np.max(df['x']), np.max(df['y']))\n",
    "\n",
    "# Generates a random rectangle inside the given interval.\n",
    "def random_rect(lx, ly, ux, uy):\n",
    "    # Generate a random lower-left vertex.\n",
    "    px = np.random.randint(lx, ux+1)\n",
    "    py = np.random.randint(ly, uy+1)\n",
    "    width = np.random.randint(0, ux-px+1)\n",
    "    height = np.random.randint(0, uy-py+1)\n",
    "    return (px, py, px+width, py+height)\n",
    "\n",
    "def to_string(rect):\n",
    "    return '({}, {}, {}, {})'.format(rect[0],rect[1],rect[2],rect[3])\n",
    "\n",
    "def queries_with_fraction(df, fmin, fmax):\n",
    "    return (df[(df.fraction >= fmin) & (df.fraction <= fmax)]).sort_values('fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eab531e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-1-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>04:30 pm</td>\n",
       "      <td>133065971</td>\n",
       "      <td>167179587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-2-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>09:10 am</td>\n",
       "      <td>132940015</td>\n",
       "      <td>166846266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-3-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11:30 am</td>\n",
       "      <td>131374822</td>\n",
       "      <td>162424128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-4-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>10:20 am</td>\n",
       "      <td>132532677</td>\n",
       "      <td>167242555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-5-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>03:30 pm</td>\n",
       "      <td>132605645</td>\n",
       "      <td>167302842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Year    Month        Day      Time          x          y\n",
       "0  2012-1-27/05/2021  2012  January     Sunday  04:30 pm  133065971  167179587\n",
       "1  2012-2-27/05/2021  2012  January     Sunday  09:10 am  132940015  166846266\n",
       "2  2012-3-27/05/2021  2012  January  Wednesday  11:30 am  131374822  162424128\n",
       "3  2012-4-27/05/2021  2012  January  Wednesday  10:20 am  132532677  167242555\n",
       "4  2012-5-27/05/2021  2012  January  Wednesday  03:30 pm  132605645  167302842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/crash_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f04655",
   "metadata": {},
   "source": [
    "# Query generation\n",
    "\n",
    "We construct a data set of $10^6$ random queries on the data set with $m=30000$ points.\n",
    "\n",
    "For each query, we measure the number of records that satisfy it.\n",
    "\n",
    "This is done by means of our <code>QueryGenerator</code> C++ program."
   ]
  },
  {
   "cell_type": "raw",
   "id": "01ddbead",
   "metadata": {},
   "source": [
    "m = 30000\n",
    "data_file = 'data/crash_data_{}.csv'.format(m)\n",
    "query_file = 'data/random_queries.csv'\n",
    "n_queries = 1000000\n",
    "params = ['../QueryGen', data_file, query_file, str(n_queries)]\n",
    "p = subprocess.run(params, capture_output=True, check=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96117b39",
   "metadata": {},
   "source": [
    "Then we consider fractions from 10% to 90%. For each fraction we select 50 queries with that fraction and create separate data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f638ab54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction: 10%\tQueries: 1696\n",
      "Fraction: 20%\tQueries: 771\n",
      "Fraction: 30%\tQueries: 461\n",
      "Fraction: 40%\tQueries: 339\n",
      "Fraction: 50%\tQueries: 332\n",
      "Fraction: 60%\tQueries: 397\n",
      "Fraction: 70%\tQueries: 532\n",
      "Fraction: 80%\tQueries: 1009\n",
      "Fraction: 90%\tQueries: 7071\n"
     ]
    }
   ],
   "source": [
    "query_file = 'data/random_queries.csv'\n",
    "query_df = pd.read_csv(query_file)\n",
    "for i in range(1, 10):\n",
    "    size = len(queries_with_fraction(query_df, i/10-0.01, i/10+0.01))\n",
    "    print('Fraction: {}%\\tQueries: {}'.format(i*10, size))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10bccc01",
   "metadata": {},
   "source": [
    "sampled_queries_per_fraction = 100\n",
    "for i in range(1, 10):\n",
    "    q_part = queries_with_fraction(query_df, i/10-0.01, i/10+0.01)\n",
    "    q_part = q_part.sample(n=sampled_queries_per_fraction)\n",
    "    q_part.to_csv('data/random_queries_{}.csv'.format(i*10), index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee847f8",
   "metadata": {},
   "source": [
    "# Fraction of records (10%-90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e6eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=30000\n",
    "c=16\n",
    "input_file = '{}/data/crash_data_{}.csv'.format(base_dir, m)\n",
    "output_file = '{}/test_query_verification/test_fraction.csv'.format(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e544b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fraction = 10%...\n",
      "Testing fraction = 20%...\n",
      "Testing fraction = 30%...\n",
      "Testing fraction = 40%...\n",
      "Testing fraction = 50%...\n",
      "Testing fraction = 60%...\n",
      "Testing fraction = 70%...\n",
      "Testing fraction = 80%...\n",
      "Testing fraction = 90%...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "f = open(output_file, 'w')\n",
    "f.write('fraction,avg_returned,avg_matching,avg_query,avg_verif\\n')\n",
    "\n",
    "os.chdir(exec_dir)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print('Testing fraction = {}%...'.format(i*10))\n",
    "    query_file = '{}/data/random_queries_{}.csv'.format(base_dir, i*10)\n",
    "    params = ['./TestQuery', input_file, query_file, str(c)]\n",
    "    p = subprocess.run(params, capture_output=True, check=True)\n",
    "    lines = p.stdout.decode('utf-8').splitlines()\n",
    "    avg_retur = int((lines[1].split(':'))[1])\n",
    "    avg_match = int((lines[2].split(':'))[1])\n",
    "    avg_query = int((lines[3].split(':'))[1])\n",
    "    avg_verif = int((lines[4].split(':'))[1])\n",
    "    f.write('{},{},{},{},{}\\n'.format(i*10,avg_retur,avg_match,avg_query,avg_verif))\n",
    "f.close()\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61e15e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "fraction &  avg\\_returned &  avg\\_matching &  noise &  avg\\_query &  avg\\_verif \\\\\n",
      "\\midrule\n",
      "     10\\% &          6186 &          2978 &  0.519 &      0.120 &      2.810 \\\\\n",
      "     20\\% &          9419 &          6014 &  0.362 &      0.187 &      4.429 \\\\\n",
      "     30\\% &         12952 &          8991 &  0.306 &      0.247 &      6.023 \\\\\n",
      "     40\\% &         16512 &         12013 &  0.272 &      0.314 &      7.629 \\\\\n",
      "     50\\% &         19132 &         15033 &  0.214 &      0.360 &      8.871 \\\\\n",
      "     60\\% &         21377 &         18019 &  0.157 &      0.398 &     10.099 \\\\\n",
      "     70\\% &         24440 &         20970 &  0.142 &      0.449 &     11.484 \\\\\n",
      "     80\\% &         26393 &         24014 &  0.090 &      0.515 &     12.438 \\\\\n",
      "     90\\% &         29001 &         27013 &  0.069 &      0.528 &     13.551 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test_query_verification/test_fraction.csv')\n",
    "# Convert returned and matching columns to integer type.\n",
    "df = df.astype({'fraction':str, 'avg_returned': int, 'avg_matching': int})\n",
    "# Add % to fraction column.\n",
    "df['fraction'] = df['fraction'] + '%'\n",
    "# Compute noise\n",
    "df['noise'] = 1-(df['avg_matching']/df['avg_returned'])\n",
    "#df['noise'] = (df['avg_returned']-df['avg_matching'])/(df['avg_returned']-2*df['avg_matching']+30000)\n",
    "# Divide by 1000 to convert microseconds to milliseconds.\n",
    "df['avg_query'] /= 1000\n",
    "df['avg_verif'] /= 1000\n",
    "# Round the execution times to 3 decimal places.\n",
    "df = df.round({'noise':3, 'avg_query': 3, 'avg_verif': 3})\n",
    "# Reorder columns.\n",
    "df = df[['fraction','avg_returned','avg_matching','noise','avg_query','avg_verif']]\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087480d",
   "metadata": {},
   "source": [
    "# Low fractions (1%-9%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cc2e8",
   "metadata": {},
   "source": [
    "Let's see how many queries we can select for each fraction from 1% to 9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c18cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction: 1%\tQueries: 18209\n",
      "Fraction: 2%\tQueries: 6504\n",
      "Fraction: 3%\tQueries: 4254\n",
      "Fraction: 4%\tQueries: 2659\n",
      "Fraction: 5%\tQueries: 1305\n",
      "Fraction: 6%\tQueries: 567\n",
      "Fraction: 7%\tQueries: 372\n",
      "Fraction: 8%\tQueries: 249\n",
      "Fraction: 9%\tQueries: 198\n"
     ]
    }
   ],
   "source": [
    "query_df = pd.read_csv('data/random_queries.csv')\n",
    "for i in range(1, 10):\n",
    "    size = len(queries_with_fraction(query_df, i/100-0.001, i/100+0.001))\n",
    "    print('Fraction: {}%\\tQueries: {}'.format(i, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617b34f",
   "metadata": {},
   "source": [
    "From these results, we see that we can select once again 100 queries for each fraction."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c24bd939",
   "metadata": {},
   "source": [
    "sampled_queries_per_fraction = 100\n",
    "query_df = pd.read_csv('data/random_queries.csv')\n",
    "for i in range(1, 10):\n",
    "    q_part = queries_with_fraction(query_df, i/100-0.001, i/100+0.001)\n",
    "    q_part = q_part.sample(n=sampled_queries_per_fraction)\n",
    "    q_part.to_csv('data/random_queries_{}.csv'.format(i), index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831371ef",
   "metadata": {},
   "source": [
    "Then we can run our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6671059",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=30000\n",
    "c=16\n",
    "input_file = '{}/data/crash_data_{}.csv'.format(base_dir, m)\n",
    "output_file = '{}/test_query_verification/test_fraction_low.csv'.format(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "181be5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fraction = 1%...\n",
      "Testing fraction = 2%...\n",
      "Testing fraction = 3%...\n",
      "Testing fraction = 4%...\n",
      "Testing fraction = 5%...\n",
      "Testing fraction = 6%...\n",
      "Testing fraction = 7%...\n",
      "Testing fraction = 8%...\n",
      "Testing fraction = 9%...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "f = open(output_file, 'w')\n",
    "f.write('fraction,avg_returned,avg_matching,avg_query,avg_verif\\n')\n",
    "\n",
    "os.chdir(exec_dir)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print('Testing fraction = {}%...'.format(i))\n",
    "    query_file = '{}/data/random_queries_{}.csv'.format(base_dir, i)\n",
    "    params = ['./TestQuery', input_file, query_file, str(c)]\n",
    "    p = subprocess.run(params, capture_output=True, check=True)\n",
    "    lines = p.stdout.decode('utf-8').splitlines()\n",
    "    avg_retur = int((lines[1].split(':'))[1])\n",
    "    avg_match = int((lines[2].split(':'))[1])\n",
    "    avg_query = int((lines[3].split(':'))[1])\n",
    "    avg_verif = int((lines[4].split(':'))[1])\n",
    "    f.write('{},{},{},{},{}\\n'.format(i,avg_retur,avg_match,avg_query,avg_verif))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec5bb567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "fraction &  avg\\_returned &  avg\\_matching &  noise &  avg\\_query &  avg\\_verif \\\\\n",
      "\\midrule\n",
      "      1\\% &          1449 &           300 &  0.793 &      0.033 &      0.631 \\\\\n",
      "      2\\% &          2003 &           601 &  0.700 &      0.044 &      0.885 \\\\\n",
      "      3\\% &          2315 &           897 &  0.613 &      0.047 &      1.005 \\\\\n",
      "      4\\% &          2603 &          1198 &  0.540 &      0.051 &      1.112 \\\\\n",
      "      5\\% &          3105 &          1499 &  0.517 &      0.062 &      1.363 \\\\\n",
      "      6\\% &          3701 &          1798 &  0.514 &      0.084 &      1.897 \\\\\n",
      "      7\\% &          4129 &          2099 &  0.492 &      0.079 &      1.832 \\\\\n",
      "      8\\% &          4578 &          2399 &  0.476 &      0.099 &      2.257 \\\\\n",
      "      9\\% &          5528 &          2701 &  0.511 &      0.111 &      2.459 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test_query_verification/test_fraction_low.csv')\n",
    "# Convert returned and matching columns to integer type.\n",
    "df = df.astype({'fraction': str, 'avg_returned': int, 'avg_matching': int})\n",
    "# Add % to fraction column.\n",
    "df['fraction'] = df['fraction'] + '%'\n",
    "# Compute noise.\n",
    "#df['noise'] = (df['avg_returned']-df['avg_matching'])/(df['avg_returned']-2*df['avg_matching']+30000)\n",
    "df['noise'] = 1-(df['avg_matching']/df['avg_returned'])\n",
    "# Divide by 1000 to convert microseconds to milliseconds.\n",
    "df['avg_query'] /= 1000\n",
    "df['avg_verif'] /= 1000\n",
    "# Round the execution times to 3 decimal places.\n",
    "df = df.round({'noise':3, 'avg_query': 3, 'avg_verif': 3})\n",
    "# Reorder columns.\n",
    "df = df[['fraction','avg_returned','avg_matching','noise','avg_query','avg_verif']]\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd327f",
   "metadata": {},
   "source": [
    "# Capacity\n",
    "\n",
    "Pick 100 queries with $f_Q \\approx 20\\%$. \n",
    "For each capacity value $c$ build a MR-tree on data set $\\mathcal{D}$.\n",
    "Then run Q and V on the 100 queries and compute an average."
   ]
  },
  {
   "cell_type": "raw",
   "id": "44d03835",
   "metadata": {},
   "source": [
    "n_queries = 200\n",
    "fq = 0.2\n",
    "query_df = pd.read_csv('data/random_queries.csv')\n",
    "q_part = queries_with_fraction(query_df, fq-0.01, fq+0.01)\n",
    "q_part = q_part.sample(n=n_queries)\n",
    "q_part.to_csv('data/random_queries_test_capacity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d269e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing capacity = 4...\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['./TestQuery', 'test/data/crash_data_30000.csv', 'test/data/random_queries_test_capacity.csv', '4']' died with <Signals.SIGSEGV: 11>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1ae586fd0288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing capacity = {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'./TestQuery'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mavg_retur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    513\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['./TestQuery', 'test/data/crash_data_30000.csv', 'test/data/random_queries_test_capacity.csv', '4']' died with <Signals.SIGSEGV: 11>."
     ]
    }
   ],
   "source": [
    "n_records = 30000\n",
    "query_file = 'test/data/random_queries_test_capacity.csv'\n",
    "input_file = 'test/data/crash_data_{}.csv'.format(n_records)\n",
    "output_file = 'test_query_verification/test_capacity.csv'\n",
    "capacities = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "f = open(output_file, 'w')\n",
    "f.write('capacity,avg_returned,avg_matching,avg_query,avg_verif\\n')\n",
    "\n",
    "os.chdir(exec_dir)\n",
    "\n",
    "for c in capacities:\n",
    "    # Run the C++ implementation.\n",
    "    print('Testing capacity = {}...'.format(c))\n",
    "    params = ['./TestQuery', input_file, query_file, str(c)]\n",
    "    p = subprocess.run(params, capture_output=True, check=True)\n",
    "    lines = p.stdout.decode('utf-8').splitlines()\n",
    "    avg_retur = int((lines[1].split(':'))[1])\n",
    "    avg_match = int((lines[2].split(':'))[1])\n",
    "    avg_query = int((lines[3].split(':'))[1])\n",
    "    avg_verif = int((lines[4].split(':'))[1])\n",
    "    f.write('{},{},{},{},{}\\n'.format(c,avg_retur,avg_match,avg_query,avg_verif))\n",
    "\n",
    "f.close()\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0cac91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " capacity &  avg\\_returned &  avg\\_matching &  noise &  avg\\_query &  avg\\_verif \\\\\n",
      "\\midrule\n",
      "        4 &          6604 &          5985 &  0.094 &      1.236 &      9.506 \\\\\n",
      "        8 &          7544 &          5985 &  0.207 &      0.935 &      6.443 \\\\\n",
      "       16 &          9436 &          5985 &  0.366 &      0.851 &      6.091 \\\\\n",
      "       32 &         13408 &          5985 &  0.554 &      1.069 &      6.678 \\\\\n",
      "       64 &         18722 &          5985 &  0.680 &      1.328 &      8.425 \\\\\n",
      "      128 &         21889 &          5985 &  0.727 &      1.489 &      9.222 \\\\\n",
      "      256 &         30000 &          5985 &  0.800 &      2.004 &     11.099 \\\\\n",
      "      512 &         30000 &          5985 &  0.800 &      2.110 &     11.126 \\\\\n",
      "     1024 &         30000 &          5985 &  0.800 &      2.017 &     11.025 \\\\\n",
      "     2048 &         30000 &          5985 &  0.800 &      2.006 &     10.918 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test_query_verification/test_capacity.csv')\n",
    "# Convert returned and matching columns to integer type.\n",
    "df = df.astype({'avg_returned': int, 'avg_matching': int})\n",
    "# Divide by 1000 to convert microseconds to milliseconds.\n",
    "df['avg_query'] /= 1000\n",
    "df['avg_verif'] /= 1000\n",
    "# Compute noise.\n",
    "df['noise'] = 1-(df['avg_matching']/df['avg_returned'])\n",
    "# Round the execution times to 3 decimal places.\n",
    "df = df.round({'noise': 3, 'avg_query': 3, 'avg_verif': 3})\n",
    "df = df[['capacity','avg_returned','avg_matching','noise','avg_query','avg_verif']]\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8934f2b7",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(\"MR-tree query and verification time (m = 30000, f ≈ 20%)\")\n",
    "plt.xticks(df['capacity'])\n",
    "plt.xscale('log', base=2)\n",
    "plt.plot(df['capacity'], df['avg_query'], marker='o', color='black', label='Avg. query')\n",
    "plt.plot(df['capacity'], df['avg_verif'], marker='o', color='grey', label='Avg. verif.')\n",
    "#plt.axvline(75, 0, 1, color='gray', linestyle='--')\n",
    "plt.ylabel(\"Time [ms]\")\n",
    "plt.xlabel(\"Page capacity (c)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"test_query_verification/test-capacity.eps\", format='eps', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
