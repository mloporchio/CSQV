{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4349209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import struct\n",
    "import subprocess\n",
    "import sys\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7de77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "exec_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ea4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns all records whose location is in the given range.\n",
    "def range_query(df, lx, ly, ux, uy):\n",
    "    return (df[(df.x >= lx) & (df.x <= ux) & (df.y >= ly) & (df.y <= uy)])\n",
    "\n",
    "# Returns the bounding rectangle of a Pandas dataframe.\n",
    "def bounding_rect(df):\n",
    "    return (np.min(df['x']), np.min(df['y']), np.max(df['x']), np.max(df['y']))\n",
    "\n",
    "# Generates a random rectangle inside the given interval.\n",
    "def random_rect(lx, ly, ux, uy):\n",
    "    # Generate a random lower-left vertex.\n",
    "    px = np.random.randint(lx, ux+1)\n",
    "    py = np.random.randint(ly, uy+1)\n",
    "    width = np.random.randint(0, ux-px+1)\n",
    "    height = np.random.randint(0, uy-py+1)\n",
    "    return (px, py, px+width, py+height)\n",
    "\n",
    "def to_string(rect):\n",
    "    return '({}, {}, {}, {})'.format(rect[0],rect[1],rect[2],rect[3])\n",
    "\n",
    "def queries_with_fraction(df, fmin, fmax):\n",
    "    return (df[(df.fraction >= fmin) & (df.fraction <= fmax)]).sort_values('fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eab531e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-1-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>04:30 pm</td>\n",
       "      <td>133065971</td>\n",
       "      <td>167179587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-2-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>09:10 am</td>\n",
       "      <td>132940015</td>\n",
       "      <td>166846266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-3-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11:30 am</td>\n",
       "      <td>131374822</td>\n",
       "      <td>162424128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-4-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>10:20 am</td>\n",
       "      <td>132532677</td>\n",
       "      <td>167242555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-5-27/05/2021</td>\n",
       "      <td>2012</td>\n",
       "      <td>January</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>03:30 pm</td>\n",
       "      <td>132605645</td>\n",
       "      <td>167302842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Year    Month        Day      Time          x          y\n",
       "0  2012-1-27/05/2021  2012  January     Sunday  04:30 pm  133065971  167179587\n",
       "1  2012-2-27/05/2021  2012  January     Sunday  09:10 am  132940015  166846266\n",
       "2  2012-3-27/05/2021  2012  January  Wednesday  11:30 am  131374822  162424128\n",
       "3  2012-4-27/05/2021  2012  January  Wednesday  10:20 am  132532677  167242555\n",
       "4  2012-5-27/05/2021  2012  January  Wednesday  03:30 pm  132605645  167302842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/crash_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f04655",
   "metadata": {},
   "source": [
    "# Query generation\n",
    "\n",
    "We construct a data set of $10^6$ random queries on the data set with $m=30000$ points.\n",
    "\n",
    "For each query, we measure the number of records that satisfy it.\n",
    "\n",
    "This is done by means of our <code>QueryGenerator</code> C++ program."
   ]
  },
  {
   "cell_type": "raw",
   "id": "01ddbead",
   "metadata": {},
   "source": [
    "m = 30000\n",
    "data_file = 'data/crash_data_{}.csv'.format(m)\n",
    "query_file = 'data/random_queries.csv'\n",
    "n_queries = 1000000\n",
    "params = ['../QueryGen', data_file, query_file, str(n_queries)]\n",
    "p = subprocess.run(params, capture_output=True, check=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96117b39",
   "metadata": {},
   "source": [
    "Then we consider fractions from 10% to 90%. For each fraction we select 50 queries with that fraction and create separate data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f638ab54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction: 10%\tQueries: 1696\n",
      "Fraction: 20%\tQueries: 771\n",
      "Fraction: 30%\tQueries: 461\n",
      "Fraction: 40%\tQueries: 339\n",
      "Fraction: 50%\tQueries: 332\n",
      "Fraction: 60%\tQueries: 397\n",
      "Fraction: 70%\tQueries: 532\n",
      "Fraction: 80%\tQueries: 1009\n",
      "Fraction: 90%\tQueries: 7071\n"
     ]
    }
   ],
   "source": [
    "query_file = 'data/random_queries.csv'\n",
    "query_df = pd.read_csv(query_file)\n",
    "for i in range(1, 10):\n",
    "    size = len(queries_with_fraction(query_df, i/10-0.01, i/10+0.01))\n",
    "    print('Fraction: {}%\\tQueries: {}'.format(i*10, size))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10bccc01",
   "metadata": {},
   "source": [
    "sampled_queries_per_fraction = 100\n",
    "for i in range(1, 10):\n",
    "    q_part = queries_with_fraction(query_df, i/10-0.01, i/10+0.01)\n",
    "    q_part = q_part.sample(n=sampled_queries_per_fraction)\n",
    "    q_part.to_csv('data/random_queries_{}.csv'.format(i*10), index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee847f8",
   "metadata": {},
   "source": [
    "# Fraction of records (10%-90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e6eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=30000\n",
    "c=16\n",
    "input_file = '{}/data/crash_data_{}.csv'.format(base_dir, m)\n",
    "output_file = '{}/test_query_verification/test_fraction.csv'.format(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e544b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fraction = 10%...\n",
      "Testing fraction = 20%...\n",
      "Testing fraction = 30%...\n",
      "Testing fraction = 40%...\n",
      "Testing fraction = 50%...\n",
      "Testing fraction = 60%...\n",
      "Testing fraction = 70%...\n",
      "Testing fraction = 80%...\n",
      "Testing fraction = 90%...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "f = open(output_file, 'w')\n",
    "f.write('fraction,avg_returned,avg_matching,avg_query,avg_verif\\n')\n",
    "\n",
    "os.chdir(exec_dir)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print('Testing fraction = {}%...'.format(i*10))\n",
    "    query_file = '{}/data/random_queries_{}.csv'.format(base_dir, i*10)\n",
    "    params = ['./TestQuery', input_file, query_file, str(c)]\n",
    "    p = subprocess.run(params, capture_output=True, check=True)\n",
    "    lines = p.stdout.decode('utf-8').splitlines()\n",
    "    avg_retur = int((lines[1].split(':'))[1])\n",
    "    avg_match = int((lines[2].split(':'))[1])\n",
    "    avg_query = int((lines[3].split(':'))[1])\n",
    "    avg_verif = int((lines[4].split(':'))[1])\n",
    "    f.write('{},{},{},{},{}\\n'.format(i*10,avg_retur,avg_match,avg_query,avg_verif))\n",
    "f.close()\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e15e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "fraction &  avg\\_returned &  avg\\_matching &  noise &  avg\\_query &  avg\\_verif \\\\\n",
      "\\midrule\n",
      "     10\\% &          6186 &          2978 &  0.519 &      0.623 &      4.336 \\\\\n",
      "     20\\% &          9419 &          6014 &  0.362 &      0.903 &      6.807 \\\\\n",
      "     30\\% &         12952 &          8991 &  0.306 &      1.250 &      9.956 \\\\\n",
      "     40\\% &         16512 &         12013 &  0.272 &      1.621 &     12.585 \\\\\n",
      "     50\\% &         19132 &         15033 &  0.214 &      1.863 &     14.718 \\\\\n",
      "     60\\% &         21377 &         18019 &  0.157 &      2.098 &     17.342 \\\\\n",
      "     70\\% &         24440 &         20970 &  0.142 &      2.370 &     19.832 \\\\\n",
      "     80\\% &         26393 &         24014 &  0.090 &      2.556 &     21.617 \\\\\n",
      "     90\\% &         29001 &         27013 &  0.069 &      2.821 &     23.893 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test_query_verification/test_fraction.csv')\n",
    "# Convert returned and matching columns to integer type.\n",
    "df = df.astype({'fraction':str, 'avg_returned': int, 'avg_matching': int})\n",
    "# Add % to fraction column.\n",
    "df['fraction'] = df['fraction'] + '%'\n",
    "# Compute noise\n",
    "df['noise'] = 1-(df['avg_matching']/df['avg_returned'])\n",
    "#df['noise'] = (df['avg_returned']-df['avg_matching'])/(df['avg_returned']-2*df['avg_matching']+30000)\n",
    "# Divide by 1000 to convert microseconds to milliseconds.\n",
    "df['avg_query'] /= 1000\n",
    "df['avg_verif'] /= 1000\n",
    "# Round the execution times to 3 decimal places.\n",
    "df = df.round({'noise':3, 'avg_query': 3, 'avg_verif': 3})\n",
    "# Reorder columns.\n",
    "df = df[['fraction','avg_returned','avg_matching','noise','avg_query','avg_verif']]\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087480d",
   "metadata": {},
   "source": [
    "# Low fractions (1%-9%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cc2e8",
   "metadata": {},
   "source": [
    "Let's see how many queries we can select for each fraction from 1% to 9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c18cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction: 1%\tQueries: 18209\n",
      "Fraction: 2%\tQueries: 6504\n",
      "Fraction: 3%\tQueries: 4254\n",
      "Fraction: 4%\tQueries: 2659\n",
      "Fraction: 5%\tQueries: 1305\n",
      "Fraction: 6%\tQueries: 567\n",
      "Fraction: 7%\tQueries: 372\n",
      "Fraction: 8%\tQueries: 249\n",
      "Fraction: 9%\tQueries: 198\n"
     ]
    }
   ],
   "source": [
    "query_df = pd.read_csv('data/random_queries.csv')\n",
    "for i in range(1, 10):\n",
    "    size = len(queries_with_fraction(query_df, i/100-0.001, i/100+0.001))\n",
    "    print('Fraction: {}%\\tQueries: {}'.format(i, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617b34f",
   "metadata": {},
   "source": [
    "From these results, we see that we can select once again 100 queries for each fraction."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c24bd939",
   "metadata": {},
   "source": [
    "sampled_queries_per_fraction = 100\n",
    "query_df = pd.read_csv('data/random_queries.csv')\n",
    "for i in range(1, 10):\n",
    "    q_part = queries_with_fraction(query_df, i/100-0.001, i/100+0.001)\n",
    "    q_part = q_part.sample(n=sampled_queries_per_fraction)\n",
    "    q_part.to_csv('data/random_queries_{}.csv'.format(i), index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831371ef",
   "metadata": {},
   "source": [
    "Then we can run our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6671059",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=30000\n",
    "c=16\n",
    "input_file = '{}/data/crash_data_{}.csv'.format(base_dir, m)\n",
    "output_file = '{}/test_query_verification/test_fraction_low.csv'.format(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181be5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fraction = 1%...\n",
      "Testing fraction = 2%...\n",
      "Testing fraction = 3%...\n",
      "Testing fraction = 4%...\n",
      "Testing fraction = 5%...\n",
      "Testing fraction = 6%...\n",
      "Testing fraction = 7%...\n",
      "Testing fraction = 8%...\n",
      "Testing fraction = 9%...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "f = open(output_file, 'w')\n",
    "f.write('fraction,avg_returned,avg_matching,avg_query,avg_verif\\n')\n",
    "\n",
    "os.chdir(exec_dir)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print('Testing fraction = {}%...'.format(i))\n",
    "    query_file = '{}/data/random_queries_{}.csv'.format(base_dir, i)\n",
    "    params = ['./TestQuery', input_file, query_file, str(c)]\n",
    "    p = subprocess.run(params, capture_output=True, check=True)\n",
    "    lines = p.stdout.decode('utf-8').splitlines()\n",
    "    avg_retur = int((lines[1].split(':'))[1])\n",
    "    avg_match = int((lines[2].split(':'))[1])\n",
    "    avg_query = int((lines[3].split(':'))[1])\n",
    "    avg_verif = int((lines[4].split(':'))[1])\n",
    "    f.write('{},{},{},{},{}\\n'.format(i,avg_retur,avg_match,avg_query,avg_verif))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5bb567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "fraction &  avg\\_returned &  avg\\_matching &  noise &  avg\\_query &  avg\\_verif \\\\\n",
      "\\midrule\n",
      "      1\\% &          1449 &           300 &  0.793 &      0.127 &      0.884 \\\\\n",
      "      2\\% &          2003 &           601 &  0.700 &      0.164 &      1.190 \\\\\n",
      "      3\\% &          2315 &           897 &  0.613 &      0.212 &      1.484 \\\\\n",
      "      4\\% &          2603 &          1198 &  0.540 &      0.245 &      1.744 \\\\\n",
      "      5\\% &          3105 &          1499 &  0.517 &      0.296 &      2.154 \\\\\n",
      "      6\\% &          3701 &          1798 &  0.514 &      0.353 &      2.478 \\\\\n",
      "      7\\% &          4129 &          2099 &  0.492 &      0.401 &      2.846 \\\\\n",
      "      8\\% &          4578 &          2399 &  0.476 &      0.447 &      3.172 \\\\\n",
      "      9\\% &          5528 &          2701 &  0.511 &      0.525 &      3.678 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test_query_verification/test_fraction_low.csv')\n",
    "# Convert returned and matching columns to integer type.\n",
    "df = df.astype({'fraction': str, 'avg_returned': int, 'avg_matching': int})\n",
    "# Add % to fraction column.\n",
    "df['fraction'] = df['fraction'] + '%'\n",
    "# Compute noise.\n",
    "#df['noise'] = (df['avg_returned']-df['avg_matching'])/(df['avg_returned']-2*df['avg_matching']+30000)\n",
    "df['noise'] = 1-(df['avg_matching']/df['avg_returned'])\n",
    "# Divide by 1000 to convert microseconds to milliseconds.\n",
    "df['avg_query'] /= 1000\n",
    "df['avg_verif'] /= 1000\n",
    "# Round the execution times to 3 decimal places.\n",
    "df = df.round({'noise':3, 'avg_query': 3, 'avg_verif': 3})\n",
    "# Reorder columns.\n",
    "df = df[['fraction','avg_returned','avg_matching','noise','avg_query','avg_verif']]\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd327f",
   "metadata": {},
   "source": [
    "# Capacity\n",
    "\n",
    "Pick 100 queries with $f_Q \\approx 20\\%$. \n",
    "For each capacity value $c$ build a MR-tree on data set $\\mathcal{D}$.\n",
    "Then run Q and V on the 100 queries and compute an average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3d6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries = 200\n",
    "fq = 0.2\n",
    "q_part = queries_with_fraction(query_df, fq-0.01, fq+0.01)\n",
    "q_part = q_part.sample(n=n_queries)\n",
    "q_part.to_csv('data/random_queries_test_capacity.csv'.format(i*10), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d269e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing capacity = 4...\n",
      "Testing capacity = 8...\n",
      "Testing capacity = 16...\n",
      "Testing capacity = 32...\n",
      "Testing capacity = 64...\n",
      "Testing capacity = 128...\n",
      "Testing capacity = 256...\n",
      "Testing capacity = 512...\n",
      "Testing capacity = 1024...\n",
      "Testing capacity = 2048...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_records = 30000\n",
    "query_file = 'test/data/random_queries_test_capacity.csv'\n",
    "input_file = 'test/data/crash_data_{}.csv'.format(n_records)\n",
    "output_file = 'test_query_verification/test_capacity.csv'\n",
    "capacities = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "f = open(output_file, 'w')\n",
    "f.write('capacity,avg_returned,avg_matching,avg_query,avg_verif\\n')\n",
    "\n",
    "os.chdir(exec_dir)\n",
    "\n",
    "for c in capacities:\n",
    "    # Run the C++ implementation.\n",
    "    print('Testing capacity = {}...'.format(c))\n",
    "    params = ['./TestQuery', input_file, query_file, str(c)]\n",
    "    p = subprocess.run(params, capture_output=True, check=True)\n",
    "    lines = p.stdout.decode('utf-8').splitlines()\n",
    "    avg_retur = int((lines[1].split(':'))[1])\n",
    "    avg_match = int((lines[2].split(':'))[1])\n",
    "    avg_query = int((lines[3].split(':'))[1])\n",
    "    avg_verif = int((lines[4].split(':'))[1])\n",
    "    f.write('{},{},{},{},{}\\n'.format(c,avg_retur,avg_match,avg_query,avg_verif))\n",
    "\n",
    "f.close()\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e0cac91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " capacity &  avg\\_returned &  avg\\_matching &  noise &  avg\\_query &  avg\\_verif \\\\\n",
      "\\midrule\n",
      "        4 &          6642 &          6000 &  0.097 &      1.358 &     11.505 \\\\\n",
      "        8 &          7609 &          6000 &  0.211 &      1.000 &      7.623 \\\\\n",
      "       16 &          9581 &          6000 &  0.374 &      0.931 &      6.881 \\\\\n",
      "       32 &         13607 &          6000 &  0.559 &      1.206 &      7.409 \\\\\n",
      "       64 &         19470 &          6000 &  0.692 &      1.512 &      9.393 \\\\\n",
      "      128 &         21480 &          6000 &  0.721 &      1.606 &      9.829 \\\\\n",
      "      256 &         30000 &          6000 &  0.800 &      2.224 &     11.881 \\\\\n",
      "      512 &         30000 &          6000 &  0.800 &      2.280 &     11.888 \\\\\n",
      "     1024 &         30000 &          6000 &  0.800 &      2.162 &     11.861 \\\\\n",
      "     2048 &         30000 &          6000 &  0.800 &      2.074 &     11.890 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('test_query_verification/test_capacity.csv')\n",
    "# Convert returned and matching columns to integer type.\n",
    "df = df.astype({'avg_returned': int, 'avg_matching': int})\n",
    "# Divide by 1000 to convert microseconds to milliseconds.\n",
    "df['avg_query'] /= 1000\n",
    "df['avg_verif'] /= 1000\n",
    "# Compute noise.\n",
    "df['noise'] = 1-(df['avg_matching']/df['avg_returned'])\n",
    "# Round the execution times to 3 decimal places.\n",
    "df = df.round({'noise': 3, 'avg_query': 3, 'avg_verif': 3})\n",
    "df = df[['capacity','avg_returned','avg_matching','noise','avg_query','avg_verif']]\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8934f2b7",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(\"MR-tree query and verification time (m = 30000, f â‰ˆ 20%)\")\n",
    "plt.xticks(df['capacity'])\n",
    "plt.xscale('log', base=2)\n",
    "plt.plot(df['capacity'], df['avg_query'], marker='o', color='black', label='Avg. query')\n",
    "plt.plot(df['capacity'], df['avg_verif'], marker='o', color='grey', label='Avg. verif.')\n",
    "#plt.axvline(75, 0, 1, color='gray', linestyle='--')\n",
    "plt.ylabel(\"Time [ms]\")\n",
    "plt.xlabel(\"Page capacity (c)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"test_query_verification/test-capacity.eps\", format='eps', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
